{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff8e645-4ea7-4fc1-bf40-945564738585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Alpha Pods Take-Home Assignment Analysis and Execution Plan\n",
    "\n",
    "I'll analyze each task at a high level before diving into detailed implementation for Task A.\n",
    "\n",
    "## High-Level Analysis of All Tasks\n",
    "\n",
    "### Task A - Baseline CVaR Index (Required)\n",
    "**Objective**: Rebuild a long-only index optimized for 95% daily Conditional Value-at-Risk (CVaR)\n",
    "**Key Components**:\n",
    "- Portfolio optimization with CVaR objective\n",
    "- Quarterly rebalancing with constraints\n",
    "- Transaction cost modeling\n",
    "- Benchmarking against equal-weighted and cap-weighted indices\n",
    "\n",
    "**Approach**: \n",
    "1. Data collection for 60 liquid S&P 100 stocks\n",
    "2. CVaR optimization implementation\n",
    "3. Backtesting framework\n",
    "4. Performance metrics calculation\n",
    "\n",
    "### Task B - Alpha Enhancement (Required)\n",
    "**Objective**: Improve risk-adjusted returns using ML/AI/statistical methods\n",
    "**Potential Approaches**:\n",
    "- Tail-risk modeling with quantile regression\n",
    "- Macro regime adaptation\n",
    "- Factor-based overlays\n",
    "- Dynamic rebalancing with RL\n",
    "\n",
    "**Key Considerations**:\n",
    "- Walk-forward validation\n",
    "- Interpretability requirements\n",
    "- Public data only constraint\n",
    "\n",
    "### Task C - Alpha in the Wild (Optional)\n",
    "**Objective**: Incorporate non-traditional data sources\n",
    "**Potential Data Sources**:\n",
    "- News sentiment analysis\n",
    "- Google Trends data\n",
    "- Social media metrics\n",
    "- Microstructure signals\n",
    "\n",
    "## Detailed Plan for Task A\n",
    "\n",
    "### 1. Data Preparation\n",
    "\n",
    "**Data Requirements**:\n",
    "- Daily price data for 60 S&P 100 stocks (Jan 2010 - Dec 2024)\n",
    "- Market cap data for benchmark construction\n",
    "- Risk-free rate for Sharpe ratio calculation\n",
    "\n",
    "**Data Sources**:\n",
    "- Yahoo Finance (yfinance)\n",
    "- Quandl or Bloomberg if available\n",
    "- FRED for risk-free rates\n",
    "\n",
    "### 2. CVaR Optimization Implementation\n",
    "\n",
    "**Mathematical Formulation**:\n",
    "```\n",
    "Minimize: CVaR_α(w) \n",
    "Subject to:\n",
    "  Σ w_i = 1 (fully invested)\n",
    "  0 ≤ w_i ≤ 0.05 (no shorting, max 5% per stock)\n",
    "```\n",
    "\n",
    "**Implementation Steps**:\n",
    "1. Calculate daily returns matrix\n",
    "2. Implement CVaR calculation using historical simulation\n",
    "3. Set up convex optimization problem (using cvxpy)\n",
    "4. Solve with quarterly rebalancing\n",
    "\n",
    "### 3. Backtesting Framework\n",
    "\n",
    "**Components**:\n",
    "- Rebalancing schedule (quarterly)\n",
    "- Transaction cost model (10bps per trade)\n",
    "- Portfolio return calculation\n",
    "- Index value computation\n",
    "\n",
    "### 4. Performance Metrics\n",
    "\n",
    "**Required Metrics**:\n",
    "- Annualized return and volatility\n",
    "- Sharpe ratio\n",
    "- 95% CVaR\n",
    "- Maximum drawdown\n",
    "- Turnover\n",
    "\n",
    "### 5. Benchmarking\n",
    "\n",
    "**Benchmarks to Include**:\n",
    "- Equal-weighted portfolio\n",
    "- Cap-weighted portfolio\n",
    "- Possibly SPY as market benchmark\n",
    "\n",
    "## Python Implementation Plan\n",
    "\n",
    "Let's start prototyping the Python implementation for Task A.\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data Collection Function\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Yahoo Finance\n",
    "    Args:\n",
    "        tickers (list): List of stock tickers\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with adjusted close prices\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} stocks from {start_date} to {end_date}\")\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "# 2. CVaR Calculation\n",
    "def calculate_cvar(returns, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Value-at-Risk (CVaR)\n",
    "    Args:\n",
    "        returns (np.array): Array of portfolio returns\n",
    "        alpha (float): Confidence level (0.95 for 95% CVaR)\n",
    "    Returns:\n",
    "        float: CVaR value\n",
    "    \"\"\"\n",
    "    var = np.percentile(returns, 100*(1-alpha))\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return cvar\n",
    "\n",
    "# 3. Portfolio Optimization\n",
    "def optimize_cvar_portfolio(returns, alpha=0.95, max_weight=0.05):\n",
    "    \"\"\"\n",
    "    Optimize portfolio weights to minimize CVaR\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame of historical returns\n",
    "        alpha (float): Confidence level for CVaR\n",
    "        max_weight (float): Maximum weight per stock\n",
    "    Returns:\n",
    "        np.array: Optimal weights\n",
    "    \"\"\"\n",
    "    n = returns.shape[1]\n",
    "    weights = cp.Variable(n)\n",
    "    \n",
    "    # Historical scenarios\n",
    "    scenario_returns = returns.values\n",
    "    portfolio_returns = scenario_returns @ weights\n",
    "    \n",
    "    # CVaR calculation using Rockafellar-Uryasev formulation\n",
    "    beta = cp.Variable()\n",
    "    tau = cp.Variable()\n",
    "    loss = -portfolio_returns\n",
    "    cvar = tau + (1/(1-alpha)) * cp.mean(cp.pos(loss - tau))\n",
    "    \n",
    "    # Problem constraints\n",
    "    constraints = [\n",
    "        cp.sum(weights) == 1,\n",
    "        weights >= 0,\n",
    "        weights <= max_weight\n",
    "    ]\n",
    "    \n",
    "    # Solve optimization problem\n",
    "    problem = cp.Problem(cp.Minimize(cvar), constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return weights.value\n",
    "\n",
    "# 4. Backtesting Engine\n",
    "def run_backtest(price_data, rebalance_freq='Q', transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Run backtest of CVaR-optimized strategy\n",
    "    Args:\n",
    "        price_data (pd.DataFrame): DataFrame of historical prices\n",
    "        rebalance_freq (str): Rebalancing frequency ('Q' for quarterly)\n",
    "        transaction_cost (float): Transaction cost per trade (10bps = 0.001)\n",
    "    Returns:\n",
    "        dict: Backtest results including portfolio values and metrics\n",
    "    \"\"\"\n",
    "    returns = price_data.pct_change().dropna()\n",
    "    dates = returns.index\n",
    "    rebalance_dates = pd.date_range(dates[0], dates[-1], freq=rebalance_freq)\n",
    "    \n",
    "    # Initialize portfolio\n",
    "    n_stocks = returns.shape[1]\n",
    "    current_weights = np.ones(n_stocks) / n_stocks  # Start with equal weights\n",
    "    portfolio_value = [1.0]  # Starting with $1\n",
    "    weights_history = []\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        date = dates[i]\n",
    "        \n",
    "        # Check if rebalance needed\n",
    "        if date in rebalance_dates:\n",
    "            # Use lookback window of 1 year for optimization\n",
    "            lookback_returns = returns.loc[:date].iloc[-252:]\n",
    "            \n",
    "            # Get optimal weights\n",
    "            new_weights = optimize_cvar_portfolio(lookback_returns)\n",
    "            \n",
    "            # Apply transaction costs\n",
    "            turnover = np.sum(np.abs(new_weights - current_weights))\n",
    "            portfolio_value[-1] *= (1 - transaction_cost * turnover)\n",
    "            \n",
    "            current_weights = new_weights\n",
    "        \n",
    "        # Record daily portfolio return\n",
    "        daily_return = np.dot(returns.iloc[i], current_weights)\n",
    "        portfolio_value.append(portfolio_value[-1] * (1 + daily_return))\n",
    "        weights_history.append(current_weights)\n",
    "    \n",
    "    results = {\n",
    "        'dates': dates,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'weights': weights_history\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# 5. Performance Metrics Calculation\n",
    "def calculate_performance_metrics(portfolio_values, benchmark_values, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics\n",
    "    Args:\n",
    "        portfolio_values (list): List of portfolio values over time\n",
    "        benchmark_values (dict): Dictionary of benchmark values\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "    Returns:\n",
    "        dict: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to returns\n",
    "    port_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Annualized return\n",
    "    annual_return = (1 + port_returns.mean())**252 - 1\n",
    "    \n",
    "    # Annualized volatility\n",
    "    annual_vol = port_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = (annual_return - risk_free_rate) / annual_vol\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # CVaR\n",
    "    cvar_95 = calculate_cvar(port_returns)\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        '95% CVaR': cvar_95,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample 60 liquid S&P 100 stocks (replace with actual list)\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'FB', 'JNJ', 'JPM', 'V', 'PG', 'HD']\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "    \n",
    "    # 2. Run backtest\n",
    "    results = run_backtest(price_data)\n",
    "    \n",
    "    # 3. Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(results['portfolio_value'], {})\n",
    "    \n",
    "    # 4. Create benchmark (equal-weighted)\n",
    "    ew_returns = price_data.pct_change().mean(axis=1).dropna()\n",
    "    ew_values = (1 + ew_returns).cumprod()\n",
    "    \n",
    "    # 5. Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['dates'], results['portfolio_value'], label='CVaR Optimized')\n",
    "    plt.plot(ew_returns.index, ew_values, label='Equal Weighted')\n",
    "    plt.title('Portfolio Performance Comparison')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Print metrics\n",
    "    print(\"Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "```\n",
    "\n",
    "## Next Steps for Task A Completion\n",
    "\n",
    "1. **Finalize the stock universe**: Identify the 60 liquid S&P 100 stocks to include\n",
    "2. **Enhance the data pipeline**: Add proper error handling for data fetching\n",
    "3. **Improve optimization stability**: Add regularization if needed\n",
    "4. **Complete benchmarking**: Add cap-weighted benchmark\n",
    "5. **Output generation**: Create CSV with daily index values and performance table\n",
    "6. **Validation**: Cross-check results against expected behavior from the paper\n",
    "\n",
    "Would you like me to elaborate on any particular aspect of this Task A implementation before we proceed to Task B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae8534e7-ff8a-44a7-b3a1-d1ddac39dbf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3820669a-4aa9-463b-a6dd-3c4de0e22814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data Collection Function\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Yahoo Finance\n",
    "    Args:\n",
    "        tickers (list): List of stock tickers\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with adjusted close prices\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} stocks from {start_date} to {end_date}\")\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "    return data\n",
    "\n",
    "# 2. CVaR Calculation\n",
    "def calculate_cvar(returns, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Value-at-Risk (CVaR)\n",
    "    Args:\n",
    "        returns (np.array): Array of portfolio returns\n",
    "        alpha (float): Confidence level (0.95 for 95% CVaR)\n",
    "    Returns:\n",
    "        float: CVaR value\n",
    "    \"\"\"\n",
    "    var = np.percentile(returns, 100*(1-alpha))\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return cvar\n",
    "\n",
    "\n",
    "# 3. Portfolio Optimization\n",
    "def optimize_cvar_portfolio(returns, alpha=0.95, max_weight=0.05):\n",
    "    \"\"\"\n",
    "    Optimize portfolio weights to minimize CVaR\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame of historical returns\n",
    "        alpha (float): Confidence level for CVaR\n",
    "        max_weight (float): Maximum weight per stock\n",
    "    Returns:\n",
    "        np.array: Optimal weights (falls back to equal weights if optimization fails)\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if returns.isnull().values.any():\n",
    "        print(\"Warning: Input returns contain NaN values - filling with zeros\")\n",
    "        returns = returns.fillna(0)\n",
    "    \n",
    "    if len(returns) < 10:  # Insufficient data points\n",
    "        print(\"Warning: Insufficient data points - returning equal weights\")\n",
    "        n = returns.shape[1]\n",
    "        return np.ones(n) / n\n",
    "    \n",
    "    n = returns.shape[1]\n",
    "    weights = cp.Variable(n)\n",
    "    \n",
    "    # Historical scenarios\n",
    "    scenario_returns = returns.values\n",
    "    portfolio_returns = scenario_returns @ weights\n",
    "    \n",
    "    # CVaR calculation using Rockafellar-Uryasev formulation\n",
    "    beta = cp.Variable()\n",
    "    tau = cp.Variable()\n",
    "    loss = -portfolio_returns\n",
    "    cvar = tau + (1/(1-alpha)) * cp.mean(cp.pos(loss - tau))\n",
    "    \n",
    "    # Problem constraints\n",
    "    constraints = [\n",
    "        cp.sum(weights) == 1,\n",
    "        weights >= 0,\n",
    "        weights <= max_weight\n",
    "    ]\n",
    "    \n",
    "    # Solve optimization problem\n",
    "    problem = cp.Problem(cp.Minimize(cvar), constraints)\n",
    "    \n",
    "    try:\n",
    "        problem.solve(solver=cp.ECOS, verbose=False)\n",
    "        if weights.value is None:\n",
    "            raise Exception(\"Solver failed to find solution\")\n",
    "        \n",
    "        # Normalize weights in case of small numerical errors\n",
    "        optimized_weights = np.maximum(weights.value, 0)\n",
    "        optimized_weights = optimized_weights / optimized_weights.sum()\n",
    "        return optimized_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {str(e)} - using equal weights as fallback\")\n",
    "        return np.ones(n) / n\n",
    "\n",
    "# 4. Backtesting Engine\n",
    "def run_backtest(price_data, rebalance_freq='Q', transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Run backtest of CVaR-optimized strategy\n",
    "    Args:\n",
    "        price_data (pd.DataFrame): DataFrame of historical prices\n",
    "        rebalance_freq (str): Rebalancing frequency ('Q' for quarterly)\n",
    "        transaction_cost (float): Transaction cost per trade (10bps = 0.001)\n",
    "    Returns:\n",
    "        dict: Backtest results including portfolio values and metrics\n",
    "    \"\"\"\n",
    "    # Calculate returns and clean data\n",
    "    returns = price_data.pct_change().dropna()\n",
    "    returns = returns.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    dates = returns.index\n",
    "    rebalance_dates = pd.date_range(dates[0], dates[-1], freq=rebalance_freq)\n",
    "    \n",
    "    # Initialize portfolio\n",
    "    n_stocks = returns.shape[1]\n",
    "    current_weights = np.ones(n_stocks) / n_stocks  # Start with equal weights\n",
    "    portfolio_value = [1.0]  # Starting with $1\n",
    "    weights_history = []\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        date = dates[i]\n",
    "        \n",
    "        # Check if rebalance needed\n",
    "        if date in rebalance_dates:\n",
    "            # Use lookback window of 1 year for optimization\n",
    "            lookback_returns = returns.loc[:date].iloc[-252:] if len(returns.loc[:date]) >= 252 else returns.loc[:date]\n",
    "            \n",
    "            # Get optimal weights\n",
    "            new_weights = optimize_cvar_portfolio(lookback_returns)\n",
    "            \n",
    "            # Apply transaction costs\n",
    "            turnover = np.sum(np.abs(new_weights - current_weights))\n",
    "            portfolio_value[-1] *= (1 - transaction_cost * turnover)\n",
    "            \n",
    "            current_weights = new_weights\n",
    "        \n",
    "        # Record daily portfolio return\n",
    "        daily_return = np.dot(returns.iloc[i], current_weights)\n",
    "        portfolio_value.append(portfolio_value[-1] * (1 + daily_return))\n",
    "        weights_history.append(current_weights)\n",
    "    \n",
    "    results = {\n",
    "        'dates': dates,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'weights': weights_history\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "# 5. Performance Metrics Calculation\n",
    "def calculate_performance_metrics(portfolio_values, benchmark_values, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics\n",
    "    Args:\n",
    "        portfolio_values (list): List of portfolio values over time\n",
    "        benchmark_values (dict): Dictionary of benchmark values\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "    Returns:\n",
    "        dict: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to returns\n",
    "    port_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Annualized return\n",
    "    annual_return = (1 + port_returns.mean())**252 - 1\n",
    "    \n",
    "    # Annualized volatility\n",
    "    annual_vol = port_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = (annual_return - risk_free_rate) / annual_vol\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # CVaR\n",
    "    cvar_95 = calculate_cvar(port_returns)\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        '95% CVaR': cvar_95,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "418a6287-c24e-4877-b961-d98dd6def227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample 60 liquid S&P 100 stocks (replace with actual list)\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'JNJ', 'JPM', 'V', 'PG']\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "    \n",
    "    # 2. Run backtest\n",
    "    results = run_backtest(price_data)\n",
    "    \n",
    "    # 3. Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(results['portfolio_value'], {})\n",
    "    \n",
    "    # 4. Create benchmark (equal-weighted)\n",
    "    ew_returns = price_data.pct_change().mean(axis=1).dropna()\n",
    "    ew_values = (1 + ew_returns).cumprod()\n",
    "    \n",
    "    # 5. Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['dates'], results['portfolio_value'], label='CVaR Optimized')\n",
    "    plt.plot(ew_returns.index, ew_values, label='Equal Weighted')\n",
    "    plt.title('Portfolio Performance Comparison')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Print metrics\n",
    "    print(\"Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dd71585-e0e2-4494-b48b-bef93344c02c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Collection and Preparation\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Yahoo Finance with enhanced error handling\n",
    "    Args:\n",
    "        tickers (list): List of stock tickers\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with adjusted close prices\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} stocks from {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        # Download data with progress bar\n",
    "        data = yf.download(tickers, start=start_date, end=end_date, progress=True)['Close']\n",
    "        \n",
    "        # Check if any stocks failed to download\n",
    "        if data.isnull().all().any():\n",
    "            failed_tickers = data.columns[data.isnull().all()].tolist()\n",
    "            print(f\"Warning: Failed to download data for {failed_tickers} - removing from universe\")\n",
    "            data = data.drop(columns=failed_tickers)\n",
    "        \n",
    "        # Forward fill missing values and drop any remaining NAs\n",
    "        data = data.ffill().dropna()\n",
    "        \n",
    "        # Verify we have sufficient data\n",
    "        if len(data) < 252:  # Less than 1 year of data\n",
    "            raise ValueError(\"Insufficient data points after cleaning\")\n",
    "            \n",
    "        print(\"Data download and cleaning completed successfully\")\n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data download: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 2. Enhanced CVaR Optimization\n",
    "def optimize_cvar_portfolio(returns, alpha=0.95, max_weight=0.05, verbose=False):\n",
    "    \"\"\"\n",
    "    Optimize portfolio weights to minimize CVaR with robust error handling\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame of historical returns\n",
    "        alpha (float): Confidence level for CVaR\n",
    "        max_weight (float): Maximum weight per stock\n",
    "        verbose (bool): Whether to print optimization details\n",
    "    Returns:\n",
    "        np.array: Optimal weights (falls back to equal weights if optimization fails)\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if returns.isnull().values.any():\n",
    "        if verbose:\n",
    "            print(\"Warning: Input returns contain NaN values - filling with zeros\")\n",
    "        returns = returns.fillna(0)\n",
    "    \n",
    "    if len(returns) < 10:  # Insufficient data points\n",
    "        if verbose:\n",
    "            print(\"Warning: Insufficient data points - returning equal weights\")\n",
    "        n = returns.shape[1]\n",
    "        return np.ones(n) / n\n",
    "    \n",
    "    n = returns.shape[1]\n",
    "    weights = cp.Variable(n)\n",
    "    \n",
    "    # Historical scenarios\n",
    "    scenario_returns = returns.values\n",
    "    portfolio_returns = scenario_returns @ weights\n",
    "    \n",
    "    # CVaR calculation using Rockafellar-Uryasev formulation\n",
    "    beta = cp.Variable()\n",
    "    tau = cp.Variable()\n",
    "    loss = -portfolio_returns\n",
    "    cvar = tau + (1/(1-alpha)) * cp.mean(cp.pos(loss - tau))\n",
    "    \n",
    "    # Problem constraints\n",
    "    constraints = [\n",
    "        cp.sum(weights) == 1,\n",
    "        weights >= 0,\n",
    "        weights <= max_weight\n",
    "    ]\n",
    "    \n",
    "    # Solve optimization problem\n",
    "    problem = cp.Problem(cp.Minimize(cvar), constraints)\n",
    "    \n",
    "    try:\n",
    "        # Try multiple solvers for robustness\n",
    "        solvers = [cp.ECOS, cp.SCS, cp.CVXOPT]\n",
    "        solution_found = False\n",
    "        \n",
    "        for solver in solvers:\n",
    "            try:\n",
    "                problem.solve(solver=solver, verbose=verbose)\n",
    "                if weights.value is not None:\n",
    "                    solution_found = True\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        if not solution_found:\n",
    "            raise Exception(\"All solvers failed to find solution\")\n",
    "        \n",
    "        # Process optimized weights\n",
    "        optimized_weights = np.maximum(weights.value, 0)  # Ensure non-negative\n",
    "        optimized_weights = optimized_weights / optimized_weights.sum()  # Re-normalize\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Optimization successful\")\n",
    "            print(f\"Optimal weights: {optimized_weights}\")\n",
    "            print(f\"Sum of weights: {optimized_weights.sum():.6f}\")\n",
    "        \n",
    "        return optimized_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Optimization failed: {str(e)} - using equal weights as fallback\")\n",
    "        return np.ones(n) / n\n",
    "\n",
    "# 3. Robust Backtesting Engine\n",
    "def run_backtest(price_data, rebalance_freq='Q', transaction_cost=0.001, verbose=False):\n",
    "    \"\"\"\n",
    "    Enhanced backtest of CVaR-optimized strategy with detailed logging\n",
    "    Args:\n",
    "        price_data (pd.DataFrame): DataFrame of historical prices\n",
    "        rebalance_freq (str): Rebalancing frequency ('Q' for quarterly)\n",
    "        transaction_cost (float): Transaction cost per trade (10bps = 0.001)\n",
    "        verbose (bool): Whether to print detailed backtest information\n",
    "    Returns:\n",
    "        dict: Backtest results including portfolio values and metrics\n",
    "    \"\"\"\n",
    "    # Calculate returns and clean data\n",
    "    returns = price_data.pct_change().dropna()\n",
    "    returns = returns.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nReturns statistics:\")\n",
    "        print(returns.describe())\n",
    "    \n",
    "    dates = returns.index\n",
    "    rebalance_dates = pd.date_range(dates[0], dates[-1], freq=rebalance_freq)\n",
    "    \n",
    "    # Initialize portfolio\n",
    "    n_stocks = returns.shape[1]\n",
    "    current_weights = np.ones(n_stocks) / n_stocks  # Start with equal weights\n",
    "    portfolio_value = [1.0]  # Starting with $1\n",
    "    weights_history = []\n",
    "    rebalance_log = []\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        date = dates[i]\n",
    "        \n",
    "        # Check if rebalance needed\n",
    "        if date in rebalance_dates:\n",
    "            # Use lookback window of 1 year for optimization\n",
    "            lookback_window = min(252, len(returns.loc[:date]))\n",
    "            lookback_returns = returns.loc[:date].iloc[-lookback_window:]\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nRebalancing on {date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"Using {len(lookback_returns)} days of returns data\")\n",
    "            \n",
    "            # Get optimal weights\n",
    "            new_weights = optimize_cvar_portfolio(lookback_returns, verbose=verbose)\n",
    "            \n",
    "            # Calculate and apply transaction costs\n",
    "            turnover = np.sum(np.abs(new_weights - current_weights))\n",
    "            cost = transaction_cost * turnover\n",
    "            portfolio_value[-1] *= (1 - cost)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Turnover: {turnover:.4f}, Transaction cost: {cost:.4%}\")\n",
    "                print(f\"Portfolio value before rebalance: {portfolio_value[-1]:.4f}\")\n",
    "            \n",
    "            current_weights = new_weights\n",
    "            rebalance_log.append({\n",
    "                'date': date,\n",
    "                'weights': current_weights,\n",
    "                'turnover': turnover,\n",
    "                'cost': cost\n",
    "            })\n",
    "        \n",
    "        # Record daily portfolio return\n",
    "        daily_return = np.dot(returns.iloc[i], current_weights)\n",
    "        portfolio_value.append(portfolio_value[-1] * (1 + daily_return))\n",
    "        weights_history.append(current_weights)\n",
    "    \n",
    "    results = {\n",
    "        'dates': dates,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'weights': weights_history,\n",
    "        'rebalance_log': pd.DataFrame(rebalance_log),\n",
    "        'returns': returns\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# 4. Comprehensive Performance Metrics\n",
    "def calculate_performance_metrics(portfolio_values, benchmark_values=None, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate detailed performance metrics with benchmark comparison\n",
    "    Args:\n",
    "        portfolio_values (list): List of portfolio values over time\n",
    "        benchmark_values (dict): Dictionary of benchmark values\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "    Returns:\n",
    "        dict: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to returns\n",
    "    port_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['Cumulative Return'] = portfolio_values[-1] / portfolio_values[0] - 1\n",
    "    metrics['Annualized Return'] = (1 + port_returns.mean())**252 - 1\n",
    "    metrics['Annualized Volatility'] = port_returns.std() * np.sqrt(252)\n",
    "    metrics['Sharpe Ratio'] = (metrics['Annualized Return'] - risk_free_rate) / metrics['Annualized Volatility']\n",
    "    \n",
    "    # Risk metrics\n",
    "    metrics['95% VaR'] = np.percentile(port_returns, 5)\n",
    "    metrics['95% CVaR'] = port_returns[port_returns <= metrics['95% VaR']].mean()\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    metrics['Max Drawdown'] = drawdown.min()\n",
    "    metrics['Avg Drawdown'] = drawdown.mean()\n",
    "    metrics['Drawdown Duration (days)'] = (drawdown < 0).astype(int).groupby((drawdown < 0).astype(int).diff().ne(0).cumsum()).max()\n",
    "    \n",
    "    # Benchmark comparison if provided\n",
    "    if benchmark_values:\n",
    "        for bench_name, bench_values in benchmark_values.items():\n",
    "            bench_returns = pd.Series(bench_values).pct_change().dropna()\n",
    "            metrics[f'Excess Return vs {bench_name}'] = metrics['Annualized Return'] - ((1 + bench_returns.mean())**252 - 1)\n",
    "            metrics[f'Tracking Error vs {bench_name}'] = (port_returns - bench_returns).std() * np.sqrt(252)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 5. Visualization and Reporting\n",
    "def generate_report(results, price_data):\n",
    "    \"\"\"\n",
    "    Generate comprehensive performance report with visualizations\n",
    "    Args:\n",
    "        results (dict): Backtest results from run_backtest\n",
    "        price_data (pd.DataFrame): Original price data\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Portfolio performance plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(results['dates'], results['portfolio_value'], label='CVaR Optimized')\n",
    "    \n",
    "    # Add equal-weighted benchmark\n",
    "    ew_returns = price_data.pct_change().mean(axis=1).dropna()\n",
    "    ew_values = (1 + ew_returns).cumprod() * results['portfolio_value'][0]\n",
    "    plt.plot(ew_returns.index, ew_values, label='Equal Weighted')\n",
    "    \n",
    "    plt.title('Portfolio Performance Comparison')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Drawdown plot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    port_returns = pd.Series(results['portfolio_value']).pct_change().dropna()\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    drawdown.plot()\n",
    "    plt.title('Portfolio Drawdown')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Drawdown')\n",
    "    plt.grid()\n",
    "    \n",
    "    # Weight distribution plot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    weights_df = pd.DataFrame(results['weights'], index=results['dates'][1:])\n",
    "    weights_df.iloc[-1].plot(kind='bar')\n",
    "    plt.title('Final Portfolio Weights')\n",
    "    plt.xlabel('Stock')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.grid()\n",
    "    \n",
    "    # Turnover analysis\n",
    "    plt.subplot(2, 2, 4)\n",
    "    results['rebalance_log'].set_index('date')['turnover'].plot()\n",
    "    plt.title('Rebalancing Turnover')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Turnover')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics\n",
    "    metrics = calculate_performance_metrics(\n",
    "        results['portfolio_value'],\n",
    "        {'Equal Weighted': ew_values}\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(\"=\"*50)\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k:<30}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:<30}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97d641c1-234c-460f-858d-6c8694de56a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample 10 liquid S&P 100 stocks for demonstration\n",
    "    # Replace with full 60 stocks for actual implementation\n",
    "    sp100_tickers = [\n",
    "        'AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META',\n",
    "        'JNJ', 'JPM', 'V', 'PG']\n",
    "    \n",
    "    print(\"Starting Alpha Pods Task A Implementation\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # 1. Fetch and prepare data\n",
    "        print(\"\\nStep 1: Fetching stock data...\")\n",
    "        price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "        \n",
    "        # 2. Run backtest\n",
    "        print(\"\\nStep 2: Running backtest...\")\n",
    "        results = run_backtest(price_data, verbose=True)\n",
    "        \n",
    "        # 3. Generate report\n",
    "        print(\"\\nStep 3: Generating performance report...\")\n",
    "        generate_report(results, price_data)\n",
    "        \n",
    "        # 4. Save results to CSV\n",
    "        print(\"\\nStep 4: Saving results...\")\n",
    "        pd.DataFrame({\n",
    "            'Date': results['dates'],\n",
    "            'Portfolio_Value': results['portfolio_value']\n",
    "        }).to_csv('cvar_index_values.csv', index=False)\n",
    "        \n",
    "        print(\"\\nTask A completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample 60 liquid S&P 100 stocks (replace with actual list)\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'JNJ', 'JPM', 'V', 'PG']\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "    \n",
    "    # 2. Run backtest\n",
    "    results = run_backtest(price_data)\n",
    "    \n",
    "    # 3. Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(results['portfolio_value'], {})\n",
    "    \n",
    "    # 4. Create benchmark (equal-weighted)\n",
    "    ew_returns = price_data.pct_change().mean(axis=1).dropna()\n",
    "    ew_values = (1 + ew_returns).cumprod()\n",
    "    \n",
    "    # 5. Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['dates'], results['portfolio_value'], label='CVaR Optimized')\n",
    "    plt.plot(ew_returns.index, ew_values, label='Equal Weighted')\n",
    "    plt.title('Portfolio Performance Comparison')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Print metrics\n",
    "    print(\"Performance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9b13f71-6ad6-4e7b-ac44-be92194f5917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Calculate performance metrics\n",
    "metrics = calculate_performance_metrics(results['portfolio_value'], {})\n",
    "\n",
    "# 4. Create benchmark (equal-weighted)\n",
    "ew_returns = price_data.pct_change().mean(axis=1).dropna()\n",
    "ew_values = (1 + ew_returns).cumprod()\n",
    "\n",
    "# 5. Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results['dates'], results['portfolio_value'], label='CVaR Optimized')\n",
    "plt.plot(ew_returns.index, ew_values, label='Equal Weighted')\n",
    "plt.title('Portfolio Performance Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 6. Print metrics\n",
    "print(\"Performance Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09114d12-c419-44d0-824d-31dccff3b708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Collection Function (Enhanced)\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Yahoo Finance with error handling\n",
    "    Args:\n",
    "        tickers (list): List of stock tickers\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with adjusted close prices\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} stocks from {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "        \n",
    "        # Check for failed downloads\n",
    "        if data.isnull().all().any():\n",
    "            failed_tickers = data.columns[data.isnull().all()].tolist()\n",
    "            print(f\"Warning: Failed to download data for {failed_tickers} - removing from universe\")\n",
    "            data = data.drop(columns=failed_tickers)\n",
    "        \n",
    "        # Clean data\n",
    "        data = data.ffill().dropna()\n",
    "        \n",
    "        if len(data) < 252:  # Less than 1 year of data\n",
    "            raise ValueError(\"Insufficient data points after cleaning\")\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data download: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 2. CVaR Calculation (Original)\n",
    "def calculate_cvar(returns, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Value-at-Risk (CVaR)\n",
    "    Args:\n",
    "        returns (np.array): Array of portfolio returns\n",
    "        alpha (float): Confidence level (0.95 for 95% CVaR)\n",
    "    Returns:\n",
    "        float: CVaR value\n",
    "    \"\"\"\n",
    "    var = np.percentile(returns, 100*(1-alpha))\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return cvar\n",
    "\n",
    "# 3. Portfolio Optimization (Enhanced)\n",
    "def optimize_cvar_portfolio(returns, alpha=0.95, max_weight=0.05):\n",
    "    \"\"\"\n",
    "    Optimize portfolio weights to minimize CVaR with fallback\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame of historical returns\n",
    "        alpha (float): Confidence level for CVaR\n",
    "        max_weight (float): Maximum weight per stock\n",
    "    Returns:\n",
    "        np.array: Optimal weights (falls back to equal weights if optimization fails)\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    returns = returns.fillna(0)\n",
    "    if len(returns) < 10:\n",
    "        n = returns.shape[1]\n",
    "        return np.ones(n) / n\n",
    "    \n",
    "    n = returns.shape[1]\n",
    "    weights = cp.Variable(n)\n",
    "    \n",
    "    # Historical scenarios\n",
    "    scenario_returns = returns.values\n",
    "    portfolio_returns = scenario_returns @ weights\n",
    "    \n",
    "    # CVaR calculation using Rockafellar-Uryasev formulation\n",
    "    beta = cp.Variable()\n",
    "    tau = cp.Variable()\n",
    "    loss = -portfolio_returns\n",
    "    cvar = tau + (1/(1-alpha)) * cp.mean(cp.pos(loss - tau))\n",
    "    \n",
    "    # Problem constraints\n",
    "    constraints = [\n",
    "        cp.sum(weights) == 1,\n",
    "        weights >= 0,\n",
    "        weights <= max_weight\n",
    "    ]\n",
    "    \n",
    "    # Solve optimization problem with fallback\n",
    "    problem = cp.Problem(cp.Minimize(cvar), constraints)\n",
    "    \n",
    "    try:\n",
    "        problem.solve(solver=cp.ECOS)\n",
    "        if weights.value is None:\n",
    "            raise ValueError(\"Solver failed to find solution\")\n",
    "            \n",
    "        # Process weights\n",
    "        optimized_weights = np.maximum(weights.value, 0)\n",
    "        optimized_weights = optimized_weights / optimized_weights.sum()\n",
    "        return optimized_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Optimization warning: {str(e)} - using equal weights\")\n",
    "        return np.ones(n) / n\n",
    "\n",
    "# 4. Backtesting Engine (Enhanced)\n",
    "def run_backtest(price_data, rebalance_freq='Q', transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Run backtest of CVaR-optimized strategy with robust handling\n",
    "    Args:\n",
    "        price_data (pd.DataFrame): DataFrame of historical prices\n",
    "        rebalance_freq (str): Rebalancing frequency ('Q' for quarterly)\n",
    "        transaction_cost (float): Transaction cost per trade (10bps = 0.001)\n",
    "    Returns:\n",
    "        dict: Backtest results including portfolio values and metrics\n",
    "    \"\"\"\n",
    "    # Calculate and clean returns\n",
    "    returns = price_data.pct_change().dropna()\n",
    "    returns = returns.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    dates = returns.index\n",
    "    rebalance_dates = pd.date_range(dates[0], dates[-1], freq=rebalance_freq)\n",
    "    \n",
    "    # Initialize portfolio\n",
    "    n_stocks = returns.shape[1]\n",
    "    current_weights = np.ones(n_stocks) / n_stocks\n",
    "    portfolio_value = [1.0]\n",
    "    weights_history = []\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        date = dates[i]\n",
    "        \n",
    "        # Rebalance logic\n",
    "        if date in rebalance_dates:\n",
    "            # Dynamic lookback window\n",
    "            lookback_window = min(252, len(returns.loc[:date]))\n",
    "            lookback_returns = returns.loc[:date].iloc[-lookback_window:]\n",
    "            \n",
    "            new_weights = optimize_cvar_portfolio(lookback_returns)\n",
    "            \n",
    "            # Apply transaction costs\n",
    "            turnover = np.sum(np.abs(new_weights - current_weights))\n",
    "            portfolio_value[-1] *= (1 - transaction_cost * turnover)\n",
    "            \n",
    "            current_weights = new_weights\n",
    "        \n",
    "        # Daily return calculation\n",
    "        daily_return = np.dot(returns.iloc[i], current_weights)\n",
    "        portfolio_value.append(portfolio_value[-1] * (1 + daily_return))\n",
    "        weights_history.append(current_weights)\n",
    "    \n",
    "    return {\n",
    "        'dates': dates,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'weights': weights_history,\n",
    "        'returns': returns\n",
    "    }\n",
    "\n",
    "# 5. Performance Metrics Calculation (Original)\n",
    "def calculate_performance_metrics(portfolio_values, benchmark_values, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics\n",
    "    Args:\n",
    "        portfolio_values (list): List of portfolio values over time\n",
    "        benchmark_values (dict): Dictionary of benchmark values\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "    Returns:\n",
    "        dict: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to returns\n",
    "    port_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Annualized return\n",
    "    annual_return = (1 + port_returns.mean())**252 - 1\n",
    "    \n",
    "    # Annualized volatility\n",
    "    annual_vol = port_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = (annual_return - risk_free_rate) / annual_vol\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # CVaR\n",
    "    cvar_95 = calculate_cvar(port_returns)\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        '95% CVaR': cvar_95,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    \n",
    "    # Benchmark comparison if provided\n",
    "    if benchmark_values:\n",
    "        for bench_name, bench_values in benchmark_values.items():\n",
    "            bench_returns = pd.Series(bench_values).pct_change().dropna()\n",
    "            metrics[f'Excess Return vs {bench_name}'] = metrics['Annual Return'] - ((1 + bench_returns.mean())**252 - 1)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Updated Market Cap Calculation with Proper Error Handling\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample liquid S&P 100 stocks\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'JNJ', 'JPM', 'V', 'PG', 'HD']\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting Alpha Pods Task A Implementation\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. Fetch price data\n",
    "        print(\"\\nStep 1: Fetching stock data...\")\n",
    "        price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "        \n",
    "        # 2. Run backtest\n",
    "        print(\"\\nStep 2: Running backtest...\")\n",
    "        results = run_backtest(price_data)\n",
    "        \n",
    "        # 3. Create benchmarks\n",
    "        print(\"\\nStep 3: Calculating benchmarks...\")\n",
    "        aligned_returns = price_data.reindex(results['dates']).pct_change().dropna()\n",
    "        \n",
    "        # Equal-weighted benchmark\n",
    "        ew_values = (1 + aligned_returns.mean(axis=1)).cumprod()\n",
    "        ew_values = ew_values * results['portfolio_value'][0]  # Normalize\n",
    "        \n",
    "        # Cap-weighted benchmark - simplified reliable approach\n",
    "        print(\"\\nCalculating market cap weights...\")\n",
    "        \n",
    "        # Get current shares outstanding from yfinance\n",
    "        shares_outstanding = {}\n",
    "        for ticker in sp100_tickers:\n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                info = stock.info\n",
    "                shares = info.get('sharesOutstanding', np.nan)\n",
    "                if not np.isnan(shares):\n",
    "                    shares_outstanding[ticker] = shares\n",
    "                else:\n",
    "                    print(f\"Warning: No shares data for {ticker} - using equal weight\")\n",
    "                    shares_outstanding[ticker] = 1  # Fallback\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting shares for {ticker}: {str(e)}\")\n",
    "                shares_outstanding[ticker] = 1  # Fallback\n",
    "        \n",
    "        # Calculate market cap weights using last available price\n",
    "        last_prices = price_data.iloc[-1]\n",
    "        valid_tickers = [t for t in sp100_tickers if t in last_prices and t in shares_outstanding]\n",
    "        \n",
    "        if valid_tickers:\n",
    "            market_caps = {ticker: last_prices[ticker] * shares_outstanding[ticker] \n",
    "                          for ticker in valid_tickers}\n",
    "            total_market_cap = sum(market_caps.values())\n",
    "            cap_weights = pd.Series({ticker: cap/total_market_cap \n",
    "                                   for ticker, cap in market_caps.items()})\n",
    "            \n",
    "            # Align weights with our returns data\n",
    "            cw_returns = (aligned_returns[cap_weights.index] * cap_weights).sum(axis=1)\n",
    "            cw_values = (1 + cw_returns).cumprod() * results['portfolio_value'][0]\n",
    "        else:\n",
    "            print(\"Warning: No valid tickers for cap weighting - skipping this benchmark\")\n",
    "            cw_values = None\n",
    "        \n",
    "        # 4. Calculate metrics\n",
    "        print(\"\\nStep 4: Calculating performance metrics...\")\n",
    "        benchmarks = {'Equal Weighted': ew_values}\n",
    "        if cw_values is not None:\n",
    "            benchmarks['Cap Weighted'] = cw_values\n",
    "            \n",
    "        metrics = calculate_performance_metrics(\n",
    "            results['portfolio_value'],\n",
    "            benchmarks\n",
    "        )\n",
    "        \n",
    "        # 5. Plot results\n",
    "        print(\"\\nStep 5: Generating plots...\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        \n",
    "        # Plot CVaR optimized portfolio\n",
    "        plt.plot(results['dates'], results['portfolio_value'], \n",
    "                label='CVaR Optimized', linewidth=2, color='blue')\n",
    "        \n",
    "        # Plot equal-weighted benchmark\n",
    "        plt.plot(ew_values.index, ew_values, \n",
    "                label='Equal Weighted', linestyle='--', color='green')\n",
    "        \n",
    "        # Plot cap-weighted benchmark if available\n",
    "        if cw_values is not None:\n",
    "            plt.plot(cw_values.index, cw_values,\n",
    "                    label='Cap Weighted', linestyle=':', color='red')\n",
    "        \n",
    "        plt.title('Portfolio Performance Comparison (2010-2024)', fontsize=14)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Portfolio Value (Normalized)', fontsize=12)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add performance metrics to plot\n",
    "        metrics_text = (\n",
    "            f\"CVaR Portfolio:\\n\"\n",
    "            f\"Ann. Return: {metrics['Annual Return']:.1%}\\n\"\n",
    "            f\"Ann. Vol: {metrics['Annual Volatility']:.1%}\\n\"\n",
    "            f\"Sharpe: {metrics['Sharpe Ratio']:.2f}\\n\"\n",
    "            f\"Max DD: {metrics['Max Drawdown']:.1%}\"\n",
    "        )\n",
    "        plt.annotate(metrics_text, xy=(0.02, 0.15), xycoords='axes fraction',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 6. Save results\n",
    "        print(\"\\nStep 6: Saving results...\")\n",
    "        output_data = {\n",
    "            'Date': results['dates'],\n",
    "            'CVaR_Portfolio': results['portfolio_value'],\n",
    "            'Equal_Weighted': ew_values\n",
    "        }\n",
    "        if cw_values is not None:\n",
    "            output_data['Cap_Weighted'] = cw_values\n",
    "            \n",
    "        pd.DataFrame(output_data).to_csv('cvar_index_values.csv', index=False)\n",
    "        \n",
    "        # Save weights at last rebalance\n",
    "        last_rebalance_weights = pd.DataFrame({\n",
    "            'Ticker': sp100_tickers,\n",
    "            'Weight': results['weights'][-1]\n",
    "        })\n",
    "        last_rebalance_weights.to_csv('final_weights.csv', index=False)\n",
    "        \n",
    "        # 7. Print metrics\n",
    "        print(\"\\nPerformance Metrics:\")\n",
    "        print(\"=\"*50)\n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, float):\n",
    "                print(f\"{k:<25}: {v:.4f}\" + (\"%\" if \"Return\" in k or \"Volatility\" in k or \"Drawdown\" in k else \"\"))\n",
    "            else:\n",
    "                print(f\"{k:<25}: {v}\")\n",
    "        \n",
    "        print(\"\\nTask A completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc2854bb-1fc2-4f7e-bb13-268500e67af6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f67887d-46a4-4c79-9047-d6fc199b1f12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2842b4f-5e05-455f-83e2-9e46619ff9a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import cvxpy as cp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Collection Function (Enhanced)\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Yahoo Finance with error handling\n",
    "    Args:\n",
    "        tickers (list): List of stock tickers\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with close prices\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} stocks from {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "        \n",
    "        # Check for failed downloads\n",
    "        if data.isnull().all().any():\n",
    "            failed_tickers = data.columns[data.isnull().all()].tolist()\n",
    "            print(f\"Warning: Failed to download data for {failed_tickers} - removing from universe\")\n",
    "            data = data.drop(columns=failed_tickers)\n",
    "        \n",
    "        # Clean data\n",
    "        data = data.ffill().dropna()\n",
    "        \n",
    "        if len(data) < 252:  # Less than 1 year of data\n",
    "            raise ValueError(\"Insufficient data points after cleaning\")\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data download: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8764ac47-ff06-4485-9a5d-afbdbea5ee93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Updated Market Cap Calculation with Proper Error Handling\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample liquid S&P 100 stocks\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'JNJ', 'JPM', 'V', 'PG', 'HD']\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting Alpha Pods Task A Implementation\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. Fetch price data\n",
    "        print(\"\\nStep 1: Fetching stock data...\")\n",
    "        price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "806c7120-410c-4156-a6fb-07c7c61ef543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55b97e8d-5adf-4462-8095-d16c3267c54c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f272b584-89c5-4ec2-a7a2-7cc196ee7c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. CVaR Calculation (Original)\n",
    "def calculate_cvar(returns, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Value-at-Risk (CVaR)\n",
    "    Args:\n",
    "        returns (np.array): Array of portfolio returns\n",
    "        alpha (float): Confidence level (0.95 for 95% CVaR)\n",
    "    Returns:\n",
    "        float: CVaR value\n",
    "    \"\"\"\n",
    "    var = np.percentile(returns, 100*(1-alpha))\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return cvar\n",
    "\n",
    "# 3. Portfolio Optimization (Enhanced)\n",
    "def optimize_cvar_portfolio(returns, alpha=0.95, max_weight=0.05):\n",
    "    \"\"\"\n",
    "    Optimize portfolio weights to minimize CVaR with fallback\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame of historical returns\n",
    "        alpha (float): Confidence level for CVaR\n",
    "        max_weight (float): Maximum weight per stock\n",
    "    Returns:\n",
    "        np.array: Optimal weights (falls back to equal weights if optimization fails)\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    returns = returns.fillna(0)\n",
    "    if len(returns) < 10:\n",
    "        n = returns.shape[1]\n",
    "        return np.ones(n) / n\n",
    "    \n",
    "    n = returns.shape[1]\n",
    "    weights = cp.Variable(n)\n",
    "    \n",
    "    # Historical scenarios\n",
    "    scenario_returns = returns.values\n",
    "    portfolio_returns = scenario_returns @ weights\n",
    "    \n",
    "    # CVaR calculation using Rockafellar-Uryasev formulation\n",
    "    beta = cp.Variable()\n",
    "    tau = cp.Variable()\n",
    "    loss = -portfolio_returns\n",
    "    cvar = tau + (1/(1-alpha)) * cp.mean(cp.pos(loss - tau))\n",
    "    \n",
    "    # Problem constraints\n",
    "    constraints = [\n",
    "        cp.sum(weights) == 1,\n",
    "        weights >= 0,\n",
    "        weights <= max_weight\n",
    "    ]\n",
    "    \n",
    "    # Solve optimization problem with fallback\n",
    "    problem = cp.Problem(cp.Minimize(cvar), constraints)\n",
    "    \n",
    "    try:\n",
    "        problem.solve(solver=cp.ECOS)\n",
    "        if weights.value is None:\n",
    "            raise ValueError(\"Solver failed to find solution\")\n",
    "            \n",
    "        # Process weights\n",
    "        optimized_weights = np.maximum(weights.value, 0)\n",
    "        optimized_weights = optimized_weights / optimized_weights.sum()\n",
    "        return optimized_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Optimization warning: {str(e)} - using equal weights\")\n",
    "        return np.ones(n) / n\n",
    "\n",
    "# 4. Backtesting Engine (Enhanced)\n",
    "def run_backtest(price_data, rebalance_freq='Q', transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Run backtest of CVaR-optimized strategy with robust handling\n",
    "    Args:\n",
    "        price_data (pd.DataFrame): DataFrame of historical prices\n",
    "        rebalance_freq (str): Rebalancing frequency ('Q' for quarterly)\n",
    "        transaction_cost (float): Transaction cost per trade (10bps = 0.001)\n",
    "    Returns:\n",
    "        dict: Backtest results including portfolio values and metrics\n",
    "    \"\"\"\n",
    "    # Calculate and clean returns\n",
    "    returns = price_data.pct_change().dropna()\n",
    "    returns = returns.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    dates = returns.index\n",
    "    rebalance_dates = pd.date_range(dates[0], dates[-1], freq=rebalance_freq)\n",
    "    \n",
    "    # Initialize portfolio\n",
    "    n_stocks = returns.shape[1]\n",
    "    current_weights = np.ones(n_stocks) / n_stocks\n",
    "    portfolio_value = [1.0]\n",
    "    weights_history = []\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        date = dates[i]\n",
    "        \n",
    "        # Rebalance logic\n",
    "        if date in rebalance_dates:\n",
    "            # Dynamic lookback window\n",
    "            lookback_window = min(252, len(returns.loc[:date]))\n",
    "            lookback_returns = returns.loc[:date].iloc[-lookback_window:]\n",
    "            \n",
    "            new_weights = optimize_cvar_portfolio(lookback_returns)\n",
    "            \n",
    "            # Apply transaction costs\n",
    "            turnover = np.sum(np.abs(new_weights - current_weights))\n",
    "            portfolio_value[-1] *= (1 - transaction_cost * turnover)\n",
    "            \n",
    "            current_weights = new_weights\n",
    "        \n",
    "        # Daily return calculation\n",
    "        daily_return = np.dot(returns.iloc[i], current_weights)\n",
    "        portfolio_value.append(portfolio_value[-1] * (1 + daily_return))\n",
    "        weights_history.append(current_weights)\n",
    "    \n",
    "    return {\n",
    "        'dates': dates,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'weights': weights_history,\n",
    "        'returns': returns\n",
    "    }\n",
    "\n",
    "# 5. Performance Metrics Calculation (Original)\n",
    "def calculate_performance_metrics(portfolio_values, benchmark_values, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics\n",
    "    Args:\n",
    "        portfolio_values (list): List of portfolio values over time\n",
    "        benchmark_values (dict): Dictionary of benchmark values\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "    Returns:\n",
    "        dict: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to returns\n",
    "    port_returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Annualized return\n",
    "    annual_return = (1 + port_returns.mean())**252 - 1\n",
    "    \n",
    "    # Annualized volatility\n",
    "    annual_vol = port_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = (annual_return - risk_free_rate) / annual_vol\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + port_returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # CVaR\n",
    "    cvar_95 = calculate_cvar(port_returns)\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        '95% CVaR': cvar_95,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    \n",
    "    # Benchmark comparison if provided\n",
    "    if benchmark_values:\n",
    "        for bench_name, bench_values in benchmark_values.items():\n",
    "            bench_returns = pd.Series(bench_values).pct_change().dropna()\n",
    "            metrics[f'Excess Return vs {bench_name}'] = metrics['Annual Return'] - ((1 + bench_returns.mean())**252 - 1)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Updated Market Cap Calculation with Proper Error Handling\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "    \n",
    "    # Sample liquid S&P 100 stocks\n",
    "    sp100_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'JNJ', 'JPM', 'V', 'PG', 'HD']\n",
    "    \n",
    "    try:\n",
    "        # print(\"Starting Alpha Pods Task A Implementation\")\n",
    "        # print(\"=\"*50)\n",
    "        \n",
    "        # # 1. Fetch price data\n",
    "        # print(\"\\nStep 1: Fetching stock data...\")\n",
    "        # price_data = fetch_stock_data(sp100_tickers, start_date, end_date)\n",
    "        \n",
    "        # 2. Run backtest\n",
    "        print(\"\\nStep 2: Running backtest...\")\n",
    "        results = run_backtest(price_data)\n",
    "        \n",
    "        # 3. Create benchmarks\n",
    "        print(\"\\nStep 3: Calculating benchmarks...\")\n",
    "        aligned_returns = price_data.reindex(results['dates']).pct_change().dropna()\n",
    "        \n",
    "        # Equal-weighted benchmark\n",
    "        ew_values = (1 + aligned_returns.mean(axis=1)).cumprod()\n",
    "        ew_values = ew_values * results['portfolio_value'][0]  # Normalize\n",
    "        \n",
    "        # Cap-weighted benchmark - simplified reliable approach\n",
    "        print(\"\\nCalculating market cap weights...\")\n",
    "        \n",
    "        # Get current shares outstanding from yfinance\n",
    "        shares_outstanding = {}\n",
    "        for ticker in sp100_tickers:\n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                info = stock.info\n",
    "                shares = info.get('sharesOutstanding', np.nan)\n",
    "                if not np.isnan(shares):\n",
    "                    shares_outstanding[ticker] = shares\n",
    "                else:\n",
    "                    print(f\"Warning: No shares data for {ticker} - using equal weight\")\n",
    "                    shares_outstanding[ticker] = 1  # Fallback\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting shares for {ticker}: {str(e)}\")\n",
    "                shares_outstanding[ticker] = 1  # Fallback\n",
    "        \n",
    "        # Calculate market cap weights using last available price\n",
    "        last_prices = price_data.iloc[-1]\n",
    "        valid_tickers = [t for t in sp100_tickers if t in last_prices and t in shares_outstanding]\n",
    "        \n",
    "        if valid_tickers:\n",
    "            market_caps = {ticker: last_prices[ticker] * shares_outstanding[ticker] \n",
    "                          for ticker in valid_tickers}\n",
    "            total_market_cap = sum(market_caps.values())\n",
    "            cap_weights = pd.Series({ticker: cap/total_market_cap \n",
    "                                   for ticker, cap in market_caps.items()})\n",
    "            \n",
    "            # Align weights with our returns data\n",
    "            cw_returns = (aligned_returns[cap_weights.index] * cap_weights).sum(axis=1)\n",
    "            cw_values = (1 + cw_returns).cumprod() * results['portfolio_value'][0]\n",
    "        else:\n",
    "            print(\"Warning: No valid tickers for cap weighting - skipping this benchmark\")\n",
    "            cw_values = None\n",
    "        \n",
    "        # 4. Calculate metrics\n",
    "        print(\"\\nStep 4: Calculating performance metrics...\")\n",
    "        benchmarks = {'Equal Weighted': ew_values}\n",
    "        if cw_values is not None:\n",
    "            benchmarks['Cap Weighted'] = cw_values\n",
    "            \n",
    "        metrics = calculate_performance_metrics(\n",
    "            results['portfolio_value'],\n",
    "            benchmarks\n",
    "        )\n",
    "        \n",
    "        # 5. Plot results\n",
    "        print(\"\\nStep 5: Generating plots...\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        \n",
    "        # Plot CVaR optimized portfolio\n",
    "        plt.plot(results['dates'], results['portfolio_value'], \n",
    "                label='CVaR Optimized', linewidth=2, color='blue')\n",
    "        \n",
    "        # Plot equal-weighted benchmark\n",
    "        plt.plot(ew_values.index, ew_values, \n",
    "                label='Equal Weighted', linestyle='--', color='green')\n",
    "        \n",
    "        # Plot cap-weighted benchmark if available\n",
    "        if cw_values is not None:\n",
    "            plt.plot(cw_values.index, cw_values,\n",
    "                    label='Cap Weighted', linestyle=':', color='red')\n",
    "        \n",
    "        plt.title('Portfolio Performance Comparison (2010-2024)', fontsize=14)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Portfolio Value (Normalized)', fontsize=12)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add performance metrics to plot\n",
    "        metrics_text = (\n",
    "            f\"CVaR Portfolio:\\n\"\n",
    "            f\"Ann. Return: {metrics['Annual Return']:.1%}\\n\"\n",
    "            f\"Ann. Vol: {metrics['Annual Volatility']:.1%}\\n\"\n",
    "            f\"Sharpe: {metrics['Sharpe Ratio']:.2f}\\n\"\n",
    "            f\"Max DD: {metrics['Max Drawdown']:.1%}\"\n",
    "        )\n",
    "        plt.annotate(metrics_text, xy=(0.02, 0.15), xycoords='axes fraction',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 6. Save results\n",
    "        print(\"\\nStep 6: Saving results...\")\n",
    "        output_data = {\n",
    "            'Date': results['dates'],\n",
    "            'CVaR_Portfolio': results['portfolio_value'],\n",
    "            'Equal_Weighted': ew_values\n",
    "        }\n",
    "        if cw_values is not None:\n",
    "            output_data['Cap_Weighted'] = cw_values\n",
    "            \n",
    "        pd.DataFrame(output_data).to_csv('cvar_index_values.csv', index=False)\n",
    "        \n",
    "        # Save weights at last rebalance\n",
    "        last_rebalance_weights = pd.DataFrame({\n",
    "            'Ticker': sp100_tickers,\n",
    "            'Weight': results['weights'][-1]\n",
    "        })\n",
    "        last_rebalance_weights.to_csv('final_weights.csv', index=False)\n",
    "        \n",
    "        # 7. Print metrics\n",
    "        print(\"\\nPerformance Metrics:\")\n",
    "        print(\"=\"*50)\n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, float):\n",
    "                print(f\"{k:<25}: {v:.4f}\" + (\"%\" if \"Return\" in k or \"Volatility\" in k or \"Drawdown\" in k else \"\"))\n",
    "            else:\n",
    "                print(f\"{k:<25}: {v}\")\n",
    "        \n",
    "        print(\"\\nTask A completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Etoro",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
